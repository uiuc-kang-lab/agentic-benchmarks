paper: https://arxiv.org/pdf/2404.07972
code: https://github.com/xlang-ai/OSWorld

I.g.1:
  check: Ground truth includes all states achievable after success.
  score: 1
  reason: As discussed in Section 3.2 of the paper, the ground truth is verified to include all states that can be achieved after a successful task completion.

I.g.2:
  check: Checks relevant and irrelevant states for the tasks.
  score: 0
  reason: The state check only verifies the relevant states for the tasks. Agents can potentially perform extra harmful actions that are not checked by the ground truth.

I.g.3:
  check: Ground truth is complex to prevent trivial state modifications.
  score: 1
  reason: AS demonstrated in Section 3.2 of the paper, the ground truth involves complex state changes to a software or website.

II.1:
  check: Versions of all tools (e.g., Python) are clearly specified.
  score: 1
  reason: No external tools are used in the benchmark. Versions of the environment are clearly specified in the README file of the repository.

II.2:
  check: All required API tools are consistently accessible to agents during evaluation.
  score: 1
  reason: No external APIs are used in the benchmark.

II.3:
  check: Evaluation process terminates or handles errors appropriately if an API becomes inaccessible.
  score: 1
  reason: No external APIs are used in the benchmark.

II.4:
  check: Residual data or state are fully cleared between runs.
  score: 1
  reason: The benchmark uses virtual machines to run the tasks, which ensures that all residual data or state are cleared between runs.

II.5:
  check: Agent is completely isolated from any ground truth information.
  score: 1
  reason: Agents and ground truth are isolated from each other via virtual machines.

II.6:
  check: Setup does not change over time (e.g., no live website).
  score: 0
  reason: The benchmark checks for HTML selectors (like class names or page titles) on live web pages.

II.7:
  check: Annotated ground truth is verified for correctness.
  score: 1
  reason: As discussed in Section 3.2 of the paper, the ground truth is verified for correctness by human experts.


II.8:
  check: Each task is verified to be solvable.
  score: 1
  reason: As discussed in Section 3.2 of the paper, each task is verified to be solvable by human experts.

II.9:
  check: Benchmark includes an Oracle solver that can automatically solve all tasks.
  score: 0
  reason: The benchmark does not include an Oracle solver that can automatically solve all tasks.

II.10:
  check: Implementation is free of vulnerabilities that could be exploited to pass evaluations without completing tasks.
  score: 1
  reason: No vulnerabilities are present in the implementation of the benchmark.

III.1:
  check: Is fully or at least partially open-sourced.
  score: 1
  reason: The benchmark is fully open-sourced, as the code is available on GitHub.

III.2:
  check: Offers an open-source evaluation harness for users.
  score: 1
  reason: The benchmark offers an open-source evaluation harness for users.

III.3:
  check: Includes measures to prevent data contamination, such as a private, held-out test set.
  score: 0
  reason: The benchmark does not include measures to prevent data contamination.

III.4:
  check: Includes measures or plans to consistently update tasks over time to avoid overfitting.
  score: 0
  reason: The report does not include measures or plans to consistently update tasks over time.

III.5:
  check: Clearly states the relationship between the agent capabilities it aims to evaluate and the constructs or outcomes it measures.
  score: 1
  reason: Such a relationship is clearly stated in Section 2 of the paper.

III.6:
  check: Clearly states the evaluation subjective of the benchmark (e.g., a model or an agent framework).
  score: 1
  reason: As discussed in Section 2 of the paper, the evaluation subject is agent frameworks.

III.7:
  check: Describes steps taken to prevent, identify, and correct flaws.
  score: 1
  reason: As discussed in Section 3.2 of the paper, the benchmark uses additional manual verification steps to prevent, identify, and correct flaws.

III.8:
  check: Includes qualitative discussions of the potential impact of unavoidable flaws.
  score: 0
  reason: Safety issues of agents are discussed in Section 7 of the paper.

III.9:
  check: Includes quantitative analysis to assess the impact of unavoidable flaws (e.g., noise of ground truth).
  score: 0
  reason: No quantitative analysis to assess the impact of unavoidable flaws is included in the report.

III.10:
  check: Reports metrics about statistical significance, such as confidence intervals.
  score: 0
  reason: The report does not include metrics about statistical significance.

III.11:
  check: Provides guidance on interpreting results with eval flaws.
  score: 0
  reason: The report does not provide guidance on interpreting results with eval flaws.

III.12:
  check: Reports results of non-AI baselines (e.g., human experts).
  score: 1
  reason: Human performace is reported in Section 3.4 of the paper.

III.13:
  check: Reports results of trivial agents (e.g., one that does nothing).
  score: 0
  reason: The report does not include results of trivial agents.
